MoodMusicApp

This project was a collaboration with a total team of four people in 2019/20.

The project extended a currently existing app. You can find more information about the application at https://cmdt.github.io/gaddum/.

As the app is existing and the extensions of the app were made for the purpose of a project, only the necessary files used in the collaborative project are added to this repository. The repository for the full application can be seen here: https://github.com/CMDT/gaddum_app




Summary of the application: The app uses facial recognition to depict the userâ€™s mood and plays a playlist depending on said mood. 
                              E.g., if the camera detects the user's facial expressions are 'happy', then a 'happy' playlist will begin to play.

Goal of project: improve the mood recognition user experience and enhance the facial recognition function.

Old version mood recognition user experience:
  -   No camera feedback: so users could not see if their face was in frame for the camera to identify their facial expressions.
  -   Character/emoji displayed to the user that represents the final detected mood of the user.
  -   Less accurate parameters to identify mood from a user's facial expressions.

The mood recognition user experience was successfully improved by:
  -   Having a heavily blurred camera feedback area: the user can see if their face is in frame without having to feel self-conscious.
  -   A grey-scale character/emoji is displayed during the process of identifying the mood of the user.
  -   When the mood is detected from a user's facial expression, a colour character/emoji representing their mood is displayed.
  -   The mood recognition process and parameters are set to be more accurate for the users.

